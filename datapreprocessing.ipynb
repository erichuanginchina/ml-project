{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0           userid  \\\n0           0  aguitarplayer94   \n1           1      aprilpooh15   \n2           2      aprilpooh15   \n3           3      aprilpooh15   \n4           4      aprilpooh15   \n\n                                                post  \\\n0  Q: what&#039;s your favorite song? :D<br>A: I ...   \n1                     Q: <3<br>A: </3 ? haha jk! <33   \n2  Q: &quot;hey angel  you duh sexy&quot;<br>A: R...   \n3                                     Q: (:<br>A: ;(   \n4  Q: ******************MEOWWW*******************...   \n\n                                                ques  \\\n0             what&#039;s your favorite song? :D<br>   \n1                                                 <3   \n2                &quot;hey angel  you duh sexy&quot;   \n3                                                 (:   \n4  ******************MEOWWW*************************   \n\n                                         ans asker  ans1  severity1 bully1  \\\n0   I like too many songs to have a favorite  None     0          0    NaN   \n1                         </3 ? haha jk! <33  None     0          0    NaN   \n2                   Really?!?! Thanks?! haha  None     0          0    NaN   \n3                                         ;(  None     0          0    NaN   \n4                                    *RAWR*?  None     0          0    NaN   \n\n   ans2  severity2 bully2  ans3  severity3 bully3  overall_ans  \\\n0     0          0    NaN     0          0    NaN            0   \n1     0          0    NaN     0          0    NaN            0   \n2     0          0    NaN     0          0    NaN            0   \n3     0          0    NaN     0          0    NaN            0   \n4     0          0    NaN     0          0    NaN            0   \n\n   overall_severity  \n0               0.0  \n1               0.0  \n2               0.0  \n3               0.0  \n4               0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>userid</th>\n      <th>post</th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>asker</th>\n      <th>ans1</th>\n      <th>severity1</th>\n      <th>bully1</th>\n      <th>ans2</th>\n      <th>severity2</th>\n      <th>bully2</th>\n      <th>ans3</th>\n      <th>severity3</th>\n      <th>bully3</th>\n      <th>overall_ans</th>\n      <th>overall_severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>aguitarplayer94</td>\n      <td>Q: what&amp;#039;s your favorite song? :D&lt;br&gt;A: I ...</td>\n      <td>what&amp;#039;s your favorite song? :D&lt;br&gt;</td>\n      <td>I like too many songs to have a favorite</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>aprilpooh15</td>\n      <td>Q: &lt;3&lt;br&gt;A: &lt;/3 ? haha jk! &lt;33</td>\n      <td>&lt;3</td>\n      <td>&lt;/3 ? haha jk! &lt;33</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>aprilpooh15</td>\n      <td>Q: &amp;quot;hey angel  you duh sexy&amp;quot;&lt;br&gt;A: R...</td>\n      <td>&amp;quot;hey angel  you duh sexy&amp;quot;</td>\n      <td>Really?!?! Thanks?! haha</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>aprilpooh15</td>\n      <td>Q: (:&lt;br&gt;A: ;(</td>\n      <td>(:</td>\n      <td>;(</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>aprilpooh15</td>\n      <td>Q: ******************MEOWWW*******************...</td>\n      <td>******************MEOWWW*************************</td>\n      <td>*RAWR*?</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 501
    }
   ],
   "source": [
    "df = pd.read_csv('clean_formspring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                post  overall_ans  \\\n0  Q: what&#039;s your favorite song? :D<br>A: I ...            0   \n1                     Q: <3<br>A: </3 ? haha jk! <33            0   \n2  Q: &quot;hey angel  you duh sexy&quot;<br>A: R...            0   \n3                                     Q: (:<br>A: ;(            0   \n4  Q: ******************MEOWWW*******************...            0   \n\n   overall_severity  \n0               0.0  \n1               0.0  \n2               0.0  \n3               0.0  \n4               0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>post</th>\n      <th>overall_ans</th>\n      <th>overall_severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Q: what&amp;#039;s your favorite song? :D&lt;br&gt;A: I ...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Q: &lt;3&lt;br&gt;A: &lt;/3 ? haha jk! &lt;33</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Q: &amp;quot;hey angel  you duh sexy&amp;quot;&lt;br&gt;A: R...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Q: (:&lt;br&gt;A: ;(</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>Q: ******************MEOWWW*******************...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 502
    }
   ],
   "source": [
    "df_new = df[['post', 'overall_ans', 'overall_severity']]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing noise from data\n",
    "import re\n",
    "\n",
    "def regex(post):\n",
    "    post = re.sub(r'[a-zA-Z0-9._%+-] + @ + [a-zA-Z0-9.-] + (\\.[a-zA-Z]{2,4})', '', post) # removing email\n",
    "    post = re.sub(r'Q\\:\\s', '', post) # removing ques & ans header\n",
    "    post = re.sub(r'A\\:\\s', '', post) # removing ques & ans header\n",
    "    post = re.sub(r'<.*?>', '', post) # removing html tags\n",
    "\n",
    "    post = re.sub(r'[^a-zA-Z0-9]',\" \", post.lower()) # removing punctuation & convert to lower case\n",
    "    post = re.sub('\\s+', ' ', post) # removing tab or more than one consecutive space\n",
    "    post = post.strip()\n",
    "    return post\n",
    "# for i in df_new.post.values[:10]:\n",
    "#     regex(i)\n",
    "\n",
    "# remove only digit token\n",
    "def rmdigit(token):\n",
    "    token = re.sub(r'^\\d+$', \"\", token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 504
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 504
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 504
    }
   ],
   "source": [
    "# tokenization\n",
    "import nltk\n",
    "import enchant\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, words\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "dict_enchant = enchant.Dict(\"en_US\")\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = regex(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # tokens = [word if dict_enchant.check(word) else dict_enchant.suggest(word)[0] for word in tokens]\n",
    "    # tokens = [word for word in tokens if dict_enchant.check(word)]\n",
    "    tokens = [word for word in tokens if len(rmdigit(word))>0]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# preparation for data modeling\n",
    "X = df_new.post.values\n",
    "y = df_new.overall_ans.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "vect = CountVectorizer(tokenizer=preprocessing)\n",
    "rfidf = TfidfTransformer()\n",
    "\n",
    "vect = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "# words -> int\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "\n",
    "X_test = vect.transform(X_test)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "for n, name in enumerate([X_train, X_test, y_train, y_test]):\n",
    "    try:\n",
    "        name = name.toarray()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    np.savez_compressed(f'{filename[n]}.npz', np.asarray(name))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbasecondac6f0cecc5cc04bfb92becad58e4c0a6a",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}